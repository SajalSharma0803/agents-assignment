# System Architecture

## High-Level Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         User's Browser                          â”‚
â”‚                    (LiveKit Client SDK)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ WebRTC (Audio)
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      LiveKit Server                             â”‚
â”‚                   (Media Routing)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Agent Protocol
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   LiveKit Agent Worker                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         SmartInterruptionAgent                            â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚    AgentSession                                    â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚   VAD    â”‚  â”‚  STT   â”‚  â”‚   LLM    â”‚  â”Œâ”€â”€â”€â”€â”€â” â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ (Silero) â”‚â†’ â”‚(Dgram) â”‚â†’ â”‚ (OpenAI) â”‚â†’ â”‚ TTS â”‚ â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜ â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â”‚                        â†“                                   â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚    InterruptionHandler (Core Logic)                â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  Decision Matrix:                            â”‚  â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Track agent state (Speaking/Silent)       â”‚  â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Analyze transcription                     â”‚  â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Check for soft words vs commands          â”‚  â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Return: Interrupt? Yes/No                 â”‚  â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Breakdown

### 1. User Interface Layer
- **LiveKit Client SDK**: Browser-based or mobile app
- **WebRTC Connection**: Real-time audio streaming
- **Microphone Input**: Captures user speech

### 2. LiveKit Server Layer
- **Media Router**: Routes audio between participants
- **Agent Protocol**: Communication with agent worker
- **Room Management**: Session handling

### 3. Agent Worker Layer

#### a. SmartInterruptionAgent
- **Orchestrates** the entire interruption handling flow
- **Monitors** TTS/STT events for state tracking
- **Coordinates** between LiveKit components and handler

#### b. AgentSession
- **VAD (Voice Activity Detection)**: Detects when user starts/stops speaking
- **STT (Speech-to-Text)**: Transcribes user speech (Deepgram)
- **LLM (Language Model)**: Generates responses (OpenAI GPT-4)
- **TTS (Text-to-Speech)**: Converts text to speech (ElevenLabs)

#### c. InterruptionHandler (Core)
- **State Tracking**: Knows if agent is Speaking or Silent
- **Text Analysis**: Parses and categorizes user input
- **Decision Logic**: Implements the interruption matrix
- **Configuration**: Manages soft words and command words

## Data Flow

### Scenario 1: User Says "Yeah" While Agent Speaking

```
1. User speaks: "yeah"
   â””â†’ VAD detects speech âš¡
      â””â†’ STT transcribes: "yeah" ðŸ“
         â””â†’ InterruptionHandler.should_interrupt()
            â”œâ”€ Check: agent_state = SPEAKING âœ“
            â”œâ”€ Check: is_only_soft_words("yeah") = True âœ“
            â””â”€ Decision: DO NOT INTERRUPT âŒ
               â””â†’ Agent continues speaking ðŸ—£ï¸
```

### Scenario 2: User Says "Stop" While Agent Speaking

```
1. User speaks: "stop"
   â””â†’ VAD detects speech âš¡
      â””â†’ STT transcribes: "stop" ðŸ“
         â””â†’ InterruptionHandler.should_interrupt()
            â”œâ”€ Check: agent_state = SPEAKING âœ“
            â”œâ”€ Check: contains_command_word("stop") = True âœ“
            â””â”€ Decision: INTERRUPT NOW âœ…
               â””â†’ Agent.cancel_speech()
                  â””â†’ TTS stops playing
                     â””â†’ Agent goes silent ðŸ”‡
```

### Scenario 3: User Says "Yeah" While Agent Silent

```
1. User speaks: "yeah"
   â””â†’ VAD detects speech âš¡
      â””â†’ STT transcribes: "yeah" ðŸ“
         â””â†’ InterruptionHandler.should_interrupt()
            â”œâ”€ Check: agent_state = SILENT âœ“
            â”œâ”€ Note: Agent is not speaking
            â””â”€ Decision: PROCESS AS VALID INPUT âœ“
               â””â†’ LLM generates response ðŸ¤–
                  â””â†’ "Great! Let's continue..."
```

## State Machine

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SILENT    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                   â”‚
       â”‚                          â”‚
       â”‚ generate_reply()         â”‚ speech_ended /
       â”‚                          â”‚ interrupted
       â–¼                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  SPEAKING   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–²
       â”‚
       â”‚ User: "yeah" â†’ IGNORED
       â”‚ User: "stop" â†’ INTERRUPT
```

## Key Design Patterns

### 1. Strategy Pattern
Different interruption strategies based on agent state:
- **Speaking Strategy**: Filter soft words, allow commands
- **Silent Strategy**: Process all input

### 2. State Pattern
Agent behavior changes based on current state:
- **SPEAKING**: Active filtering
- **SILENT**: No filtering

### 3. Observer Pattern
Monitor events from multiple sources:
- TTS events â†’ Update agent state
- STT events â†’ Process transcriptions
- VAD events â†’ Detect speech activity

## Critical Implementation Details

### 1. Race Condition Handling

**Problem**: VAD fires before STT completes transcription

```
Timeline:
0ms    - User starts speaking "yeah"
10ms   - VAD detects speech START
20ms   - VAD could trigger interruption
200ms  - STT completes: "yeah"
```

**Solution**: Delay interruption decision until transcription available

```python
async def handle_vad_event():
    await asyncio.sleep(transcription_delay)
    # Now we have the transcription
    should_interrupt, _ = await handler.should_interrupt(text)
```

### 2. State Synchronization

**Problem**: Multiple async events updating state

**Solution**: Use asyncio locks

```python
self._state_lock = asyncio.Lock()

async def set_agent_state(state):
    async with self._state_lock:
        self.agent_state = state
```

### 3. Text Normalization

**Problem**: "Yeah!", "yeah", "YEAH" should be treated the same

**Solution**: Normalize before comparison

```python
def _normalize_text(text: str) -> str:
    return text.lower().strip().rstrip('.,!?')
```

## Performance Characteristics

| Metric | Value | Notes |
|--------|-------|-------|
| **Decision Latency** | <10ms | Time to decide interrupt/ignore |
| **Transcription Delay** | 200-300ms | Configurable, prevents false starts |
| **Memory Overhead** | <5MB | Minimal state tracking |
| **CPU Impact** | <1% | Text processing is lightweight |
| **Concurrent Users** | 100+ | Per worker instance |

## Scalability

### Horizontal Scaling
- Each worker instance handles multiple concurrent sessions
- Workers can be distributed across multiple machines
- LiveKit server handles load balancing

### Resource Usage Per Session
- **Memory**: ~10-20MB
- **CPU**: ~2-5% during active speech
- **Network**: Handled by LiveKit server

## Testing Strategy

### 1. Unit Tests
Test individual components in isolation:
- `InterruptionHandler` logic
- Text normalization
- State transitions

### 2. Integration Tests
Test components working together:
- Event flow from STT to decision
- State synchronization

### 3. End-to-End Tests
Test complete scenarios:
- Real conversations
- All test cases from requirements

### 4. Performance Tests
Ensure latency requirements:
- Decision time < 10ms
- No dropped audio frames

## Extension Points

### Adding New Soft Words
```python
config = InterruptionConfig(
    soft_words={'yeah', 'ok', 'custom_word'},
    command_words={'stop', 'wait', 'no'}
)
```

### Adding Language Support
```python
# Spanish support
config_es = InterruptionConfig(
    soft_words={'sÃ­', 'vale', 'ajÃ¡'},
    command_words={'espera', 'para', 'no'}
)
```

### Custom Decision Logic
```python
class CustomInterruptionHandler(InterruptionHandler):
    async def should_interrupt(self, text, confidence):
        # Your custom logic here
        pass
```

## Troubleshooting Guide

| Issue | Possible Cause | Solution |
|-------|---------------|----------|
| Agent pauses on "yeah" | State not tracked correctly | Verify TTS event hooks |
| Commands don't interrupt | Command words not in config | Check config.command_words |
| High latency | Transcription delay too high | Reduce transcription_delay |
| False positives | Low STT confidence | Increase confidence_threshold |

## Future Enhancements

1. **ML-Based Detection**: Use ML model to classify interruptions
2. **Context Awareness**: Consider conversation context
3. **Speaker Recognition**: Different rules per speaker
4. **Sentiment Analysis**: Factor in user emotion
5. **Multi-Language**: Auto-detect language and switch word lists
